{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3561f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "from gensim import corpora\n",
    "from collections import defaultdict\n",
    "from gensim import similarities\n",
    "from gensim import models\n",
    "import json\n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "from googletrans import Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13558bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading json file\n",
    "def load_data(file):\n",
    "    with open (file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f) \n",
    "    return (data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed189168",
   "metadata": {},
   "outputs": [],
   "source": [
    "#append data to json file\n",
    "def append_data(file, data):\n",
    "    with open (file, \"a\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef78ffe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write json file\n",
    "def write_data(file, data):\n",
    "    with open (file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b66c147c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Translate(data): #List of List\n",
    "    translator = Translator()\n",
    "    docs = []\n",
    "    for article in dat:\n",
    "        translated_text = translator.translate(article[0],dest='en') #This will change\n",
    "        #print(translated_text.text)\n",
    "        #print()\n",
    "        d=translated_text.text\n",
    "        docs.append([d,article[1]])  #This too depending on our DB\n",
    "    return docs #List of List "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5031b533",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treat data \n",
    "def Treat_Data(docs): #List of List \n",
    "    #Creating a list of stopwords\n",
    "    stoplist = set('for a of the and to in'.split()) \n",
    "    #Removing stopwords ( Depends on BD too )\n",
    "    txts = [[word for word in document[0].lower().split() if word not in stoplist]for document in docs]\n",
    "    #Calculating frequency of each word \n",
    "    frequency = defaultdict(int)\n",
    "    for text in txts:\n",
    "        for token in text:\n",
    "            frequency[token] += 1\n",
    "    #Removing words that appear only once\n",
    "    txts = [[token for token in text if frequency[token] > 1]for text in txts]\n",
    "    #Creating a dictionary\n",
    "    gensim_dictionary = corpora.Dictionary(txts)\n",
    "    #Vectorizing the corpus\n",
    "    gensim_corpus = [gensim_dictionary.doc2bow(text) for text in txts]\n",
    "    #print(gensim_corpus)\n",
    "    return gensim_corpus,gensim_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d97a19f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bd12c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSI(gensim_corpus,gensim_dictionary): #creating LSI model\n",
    "    lsi = models.LsiModel(gensim_corpus, id2word=gensim_dictionary, num_topics=2)\n",
    "    return lsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea1254fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''-----Treating the query-------\n",
    "    Query is the document that will be compared to \n",
    "    Doc is an article '''\n",
    "def Treat_Query(doc):\n",
    "    #Creating bow vector\n",
    "    vec_bow = gensim_dictionary.doc2bow(doc.lower().split())\n",
    "    #Converting the query to LSI space\n",
    "    vec_lsi = lsi[vec_bow]  \n",
    "    return vec_lsi\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7991352a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Similarity(vec_lsi,gensim_corpus,lsi):\n",
    "    index = similarities.MatrixSimilarity(lsi[gensim_corpus])  \n",
    "    simil = index[vec_lsi]  \n",
    "    simil=sorted(list(enumerate(simil)),key=lambda item: -item[1])\n",
    "    #print(simil)\n",
    "    #print('###########################################################################################')\n",
    "    return simil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ef3eee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Match_Sim(docs,simil,nbsim): #Match similar articles with a special id\n",
    "    for doc_position, doc_score in simil:\n",
    "        #print(\"the score is : \",doc_score)\n",
    "        #print(docs[doc_position][0])  \n",
    "        #print()\n",
    "        if doc_score>0.90: \n",
    "            docs[doc_position][1] = nbsim \n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "740d65b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['The services of the PAF at Houari Boumediene airport in Algiers have succeeded in foiling a new attempt at the illicit transfer of capital. Indeed, they proceeded to seize a large sum in euros, but also in dollars on a passenger who was about to travel to Turkey. Coming from Tizi Ouazou, the traveler in question was about to take his flight to Istanbul. During an ordinary baggage check. Elements of the border police at Algiers airport. They discovered 50,000 euros and 5,000 dollars, carefully concealed in his belongings. According to the Arabic-speaking Ennahar who reported the information, the PAF arrested this passenger. And the seizure of this large sum. An investigation was launched and the accused was presented on Wednesday, August 31, before the court of Dar El Beida, located in Algiers. And this, for violation of the regulations governing the transfer of capital from and to Algeria. During his hearings, the traveler from Tizi Ouazou declared that this money. Was destined for surgery. Which he intended to suffer, in Turkey. In addition, this defendant maintained that he suffered from an illness requiring an operation abroad. To support his remarks, the mis en cause presented some medical documents attesting to his state of health, affirms the same source. On the other hand, even if the defense of this passenger made it known that this trip was a first for the latter. The public prosecutor in charge of his case decided otherwise. Indeed, he asked to inflict on him the sentence of one year of imprisonment, accompanied by a large fine to pay. The verdict should be pronounced in the coming days.', 1], ['The defending champion of the English Premier League, the club of Manchester City, continues to fly over the flagship championship of the British kingdom. Indeed, after a difficult victory during the previous day of the championship against the London club of Cristal Palace, the men of the Catalan technician, Pep Guardiola, had the strong hand against their opponent of the day, the club of Nottingham Forest. Thus, for the reception of the promoted, the Cityzens showed off their offensive power. Enterprising and showing pressure on the opposing camp from the first minutes, the Manchester City players were rewarded by the opener in the 12th minute of the game. This first goal of what later proved to be a offensive ball bears the signature of the Norwegian striker, Erling Haaland. The new City striker did not stop on this last goal and doubled, and even tripled the lead for his team-mates in the space of 38 minutes.FULL-TIME | A fine home performance!', 1], ['Relaunch of the Midcat gas pipeline project: The Forcing of Spain comes up against the reluctance of France The last meeting of Spanish Prime Minister Pedro Sanchez and German Chancellor Olaf Scholz had as its main object the relaunch of the Midcat gas pipeline project, likely to improve the interconnections of the gas network in Europe. The route of this gas pipeline starts from the Iberian Peninsula, crosses France and reaches Central Europe. It is thought of as an alternative, which would reduce the tensions on the deliveries of Russian gas, generated by the war in Ukraine. Especially since Germany and Spain are greatly affected by the energy crisis. Except that the reluctance of France, an essential partner, dulls the frenzy of the Spaniards, the Germans, and to a lesser extent the Portuguese. It advances the same arguments as those that led to the suspension of the project in 2019: it is too expensive, does not ideally meet the objectives related to securing supplies and has a negative impact on the environment. The French Minister of Economy and Finance Bruno Le Maire does not, however, oppose a categorical niet. Spain and Germany are two very close partners of France. So when they make a proposal, we will examine it, he suggested, on the sidelines of a meeting with Entrepreneurs de France. since it is essentially intended to distribute, to other European countries, Algerian gas supplied to Spain. Considering that this country has insidiously complicated its situation by falling out with Algiers, the said project risks remaining an idea transcribed on paper.S B.', 2]]\n"
     ]
    }
   ],
   "source": [
    "#GENERAL CODE\n",
    "\n",
    "#This might change with Mysql \n",
    "dat = []\n",
    "nbsim = 0\n",
    "data = load_data(\"./dataFR.json\")['texts']\n",
    "for i in range(len(data)):\n",
    "    dat.append([data[i][\"text\"],0])\n",
    "#print(dat)\n",
    "docs = Translate(dat)\n",
    "gensim_corpus,gensim_dictionary = Treat_Data(docs)\n",
    "lsi = LSI(gensim_corpus,gensim_dictionary)\n",
    "for i in range(len(docs)):\n",
    "    if docs[i][1] == 0: #Depends on MYSQL\n",
    "        vec_lsi = Treat_Query(docs[i][0])\n",
    "        simil = Similarity(vec_lsi,gensim_corpus,lsi)\n",
    "        nbsim += 1\n",
    "        docs = Match_Sim(docs,simil,nbsim)\n",
    "print(docs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
